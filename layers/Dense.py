#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Feb  2 08:57:00 2021

@author: nuvilabs
"""
[]
import numpy as np
import matplotlib.pyplot as plt
import nnfs
from nnfs.datasets import spiral_data
class Layer_Dense:
    # Layer initialization
    def __init__(self, n_inputs, n_neurons, weight_regularizer_l1=0, weight_regularizer_l2=0, bias_regularizer_l1=0, bias_regularizer_l2=0):
        """
        Weâ€™re going to multiply this
        Gaussian distribution for the weights by 0.01 to generate numbers that are a couple of magnitudes
        smaller. Otherwise, the model will take more time to fit the data during the training process
        as starting values will be disproportionately large compared to the updates being made during
        training. The idea here is to start a model with non-zero values small enough that they wonâ€™t affect
        training. This way, we have a bunch of values to begin working with, but hopefully none too large
        or as zeros. You can experiment with values other than 0.01 if you like.
        """
        self.weights = 0.1 * np.random.randn(n_inputs,n_neurons)
        self.biases = np.zeros((1, n_neurons))
        self.weight_regularizer_l1 = weight_regularizer_l1
        self.weight_regularizer_l2 = weight_regularizer_l2
        self.bias_regularizer_l1 = bias_regularizer_l1
        self.bias_regularizer_l2 = bias_regularizer_l2
    # Forward pass
    def forward(self, inputs, training):
        # Calculate output values from inputs, weights and biases
        self.inputs = inputs
        self.output = np.dot(inputs, self.weights) + self.biases
    def backward(self, dvalues):
        #davlues.shape = (batch_size, neurons)
        self.dweights = np.dot(self.inputs.T,dvalues)  #=> (n_inputs,n_neurons)
        self.dbiases = np.sum(dvalues,axis = 0,keepdims=True) #=>(1,n_neurons)
        #L1 on weights
        if self.weight_regularizer_l1 > 0:
            dL1 = np.ones_like(self.weights)
            dL1[self.weights < 0] = -1
            self.dweights += self.weight_regularizer_l1 * dL1
        #L2 on weights
        if self.weight_regularizer_l2 > 0:
            self.dweights += 2 * self.bias_regularizer_l2 * self.weights
        #L1 on biases
        if self.bias_regularizer_l1 > 0:
            dL1 = np.ones_like(self.biases)
            dL1[self.biases < 0] = -1
            self.dbiases += self.bias_regularizer_l1 * dL1
        #L2 on biases
        if self.bias_regularizer_l2 > 0:
            self.dbiases = 2 * self.bias_regularizer_l2 * self.biases
        # Gradient on values
        self.dinputs = np.dot(dvalues,self.weights.T) #=>(batch_size,n_inputs)
    def get_parameters(self):
        return self.weights, self.biases
    # Set weights and biases in a layer instance
    def set_parameters(self, weights, biases):
        self.weights = weights
        self.biases = biases

